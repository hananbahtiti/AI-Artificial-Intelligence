{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_end.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEltm1WG-cn2"
      },
      "source": [
        "!pip uninstall libav-tools\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb5jPYVB-nMn"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzT1jIRqBELi"
      },
      "source": [
        "pip install  soundfile "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7p9DUXVwOSB"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import soundfile as sf\n",
        "import difflib\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "from keras.regularizers import l1\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfLbiZ7SwRHZ"
      },
      "source": [
        "labels = []\n",
        "with open('/content/drive/My Drive/all_data.csv', 'r') as read_obj:\n",
        "    # pass the file object to reader() to get the reader object\n",
        "    csv_reader = csv.reader(read_obj)\n",
        "    # Iterate over each row in the csv using reader object\n",
        "    for row in csv_reader:\n",
        "        # row variable is a list that represents a row in csv\n",
        "        labels.append(row[1])\n",
        "labels.remove('label')\n",
        "\n",
        "print(len(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aA8jy68wc7j"
      },
      "source": [
        "all_wave = np.load(\"/content/drive/My Drive/50all_wave.npy\", allow_pickle=True) \n",
        "all_label = np.load(\"/content/drive/My Drive/50all_label.npy\", allow_pickle=True) \n",
        "print(len(all_label))\n",
        "print(len(all_wave))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-j6BAoGwkZv"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y=le.fit_transform(all_label)\n",
        "classes= list(le.classes_)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFHdmpSdwmbB"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y=np_utils.to_categorical(y, num_classes=len(labels))\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T9H-FUEwomM"
      },
      "source": [
        "all_wave = np.array(all_wave).reshape(-1,884  ,1)\n",
        "print(all_wave.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nObP-JQqccLG"
      },
      "source": [
        "all_waves = np.array(all_wave)\n",
        "y = np.array(y)\n",
        "all_waves = all_waves.reshape(72100  ,884 ,1)\n",
        "all_wave = all_wave.reshape(all_waves.shape)\n",
        "all_waves = all_waves.transpose()\n",
        "all_waves = all_waves.reshape((884,72100 ,1))\n",
        "print(all_waves.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrvnPabYwrnB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test  = train_test_split(all_waves,y,  test_size = 0.2,random_state=777,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T27xD7puEnes"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VESvCUo0wwfV"
      },
      "source": [
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.regularizers import l1 \n",
        "\n",
        "# instantiate regularizer\n",
        "reg = l1(0.001)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "inputs = Input(shape=(72100, 1))\n",
        "\n",
        "#First Conv1D layer\n",
        "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Second Conv1D layer\n",
        "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Third Conv1D layer\n",
        "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Fourth Conv1D layer\n",
        "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
        "conv = MaxPooling1D(3)(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Flatten layer\n",
        "conv = Flatten()(conv)\n",
        "\n",
        "#Dense Layer 1\n",
        "conv = Dense(256, activation='relu' ,activity_regularizer=l1(0.001))(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "#Dense Layer 2\n",
        "conv = Dense(128, activation='relu' ,activity_regularizer=l1(0.001))(conv)\n",
        "conv = Dropout(0.3)(conv)\n",
        "\n",
        "outputs = Dense(len(labels), activation='softmax')(conv)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkNHnDya0-kF"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv6btidkw1DY"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUtNWmd3rcti"
      },
      "source": [
        "X_train = tf.convert_to_tensor(X_train, np.float32)\n",
        "y_train = tf.convert_to_tensor(y_train, np.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, np.float32)\n",
        "y_test = tf.convert_to_tensor(y_test, np.float32)\n",
        "history= model.fit(X_train, y_train ,epochs=300, batch_size=128, validation_data=(X_test,y_test),callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73N_5wJVw5Y7"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
        "mc = ModelCheckpoint('model.h5', monitor='val_acc', verbose=1, save_best_only= True ,mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReFb-6Jc7e1U"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZTb10dYkiND"
      },
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/My Drive/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR5twRXGos0s"
      },
      "source": [
        "def predict(audio):\n",
        "    prob=model.predict(audio.reshape(1,72100,1))\n",
        "    index=np.argmax(prob[0])\n",
        "    return classes[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaHlia88o_iY"
      },
      "source": [
        "import random\n",
        "index=random.randint(0,len(X_test)-1)\n",
        "#samples = X_test[index].ravel()\n",
        "samples = np.ravel(X_test[index])\n",
        "print(\"Audio:\",classes[np.argmax(y_test[index])])\n",
        "ipd.Audio(samples, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaaEma-Gs8PQ"
      },
      "source": [
        "b = print(\"Text:\",predict(samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdLHGkMbP1is"
      },
      "source": [
        "a = predict(samples)\n",
        "b = ['و رجح التقرير الذي أعده معهد أبحاث هضبة التبت في الأكاديمية الصينية للعلوم أن تستمر درجات الحرارة و مستويات الرطوبة في الارتفاع طوال هذا القرن مما قد يؤدي إلى تراجع مساحات الأنهار الجليدية وانتشارِ التصحر و ذكر التقرير أن تراجع مساحة الجليد يمكن أن يخلى بمعدلات امدادات المياه لعدد من أنهار آسيا الرئيسية التي تنبع من الهضبة' , 'يرتبط الورد بين الناس بصباحات و المساءات و الهدايا و أما عند أهل الطائف فهو ارتباط روحي و تاريخي و عشق متبادل و يسقونه و يعرفونه  كما يعرفهم منذ القرن التاسع الهجري و أعبقها ما يروى من مياه المطر وفي كل عاما من موسم الورد الطائفي نهاية آذار و أوائل نيسان تروى قصة حب بينه و بين أهله على قمم و سفوح جبال الطائف' , 'مجموعة من علماء النفس الأمريكيين توصلوا لسبب ذلك وهو أن دموع الفرح قد تكون طريقة الجسم الصحيحة لاستعادة التوازن العاطفي بهذه التعبيرات' , 'و الشوكولاتة هي أسرع في الذوبان من الزبدة و تحتاج فقط لدرجة حرارة انصهار تبلغ حوالي ثلاثة و ثلاثين درجة مئوية أي أقل من درجة حرارة الإنسان لذلك تذوب الشوكولاتة بسهولة على اللسان بحرارة اللعاب فقط' , 'و يضم المعرض نسخا نادرة من المصاحف المذهبة و أخرى مخطوطة لا يتجاوز حجمها كف اليد و أخرى كبيرة تزيد مساحة ضلع الصفحة فيها عن خمسة و ستين سنتمتر  فضلا عن نسخ مترجمة لمعاني القرآن كتبت بحروف بريل الإنكليزية للقراء المكفوفين' , 'تقوم على إطلاق مئات الأقمار الصناعية المصغرة إلى مدار منخفض حول الأرض بحيث يتولى كل قمر صناعي باستقبال البيانات من عدة مئات من المحطات الأرضية ثم إعادة بثها عبر موجات إذاعية عريضة  إلى الهواتف المنتشرة في العالم' , 'كشفت دراسة أمريكية أن المشاعر الأساسية الستة سعيد و حزين و خائف و غضبان و مندهش و مشمئز لا تغطي كل التعابير التي تظهر على الوجه كما كان يعتقد و بعضها معقد مثل مشمئز بسعادة و غضبان بحزن' , 'يعد العلاج بالأحجار الكريمة من طرق السائدة في الشرق القديم حيث كان العرب أول من عرف قيمتها العلاجية في القرن العاشر قبل الميلاد في مملكة سبأ فطلبها الفراعنة للزينة و التبرك والعلاج' , 'طور علماء هولنديون أول بديل فعال عن المضادات الحيوية و هو ما يعتبر تقدم هام في مكافحة العدوى المقاومة للأدوية و يأمل الباحثون تطوير حبوب من الدواء خلال خمسة سنوات' , 'تسعى السعودية إلى تحقيق طفرة في مستقبل الرعاية الصحية بالمملكة من خلال مشروع جديد لرسم خرائط الجينوم البشري يستمر خمس سنوات لتكوين قاعدة بيانات للحمض النووي ليستخدمها العلماء في مختلف الأغراض' , 'أفادت دراسة جديدة بأن الصيام لمدة أقل من ثلاثة أيام يمكن أن يجدد نشاط الجهاز المناعي بأكمله حتى في كبار السن و أشارت الدراسة إلى أن تجويع الجسم يحفز الخلايا الجذعية على تجديد خلايا الدم البيضاء المقاومة  للعدوى مما يزيد صعوبة مقاومتهم للأمراض الشائعة' , 'و يقوم هذا التصميم على التخفيف من ازدحام الأيقونات و الخيارات و التركيز على الخريطة و تسهيل عملية استكشاف الأماكن الجديدة و تدعم النسخة الجديدة من خرائط جوجل إظهار معلومات الطريق في الوقت الحقيقي و كما يقترح التطبيق و بشكل فوري طريق بديل لمساعدة المستخدم في تفادي الازدحام' , 'و قال العلماء إن مثل هذه الأفكار تزيد فهمهم لكيفية تعبير الناس عن عواطفهم و مراقبتها و لما هذا من ارتباط مهم بالصحة النفسية و الجسدية و نوعية العلاقات مع الآخرين بل حتى كيفية تعامل الناس مع بعضهم بشكل جيد' , 'و يقول باحثون إن هذه الدراسة تظهر الحاجة لمراجعة التوجيهات الإرشادية الحالية التي تنصح بإنقاص الوزن بخطى بطيئة و ثابتة و يقول كبير الباحثين في الفريق  إن السمنة المفرطة ليست مرض نابع من نمط الحياة فحسب وفق الاعتقاد الشائع' , 'تثير السيجارة الإلكترونية الكثير من الجدل بين كونها وسيلة صحية لتخلص من التدخين أو بضاعة تجارية يعمل منتجوها على تحسينها باستمرار للفوز برضى الزبائن' , 'التوحد هو مجموعة اضطرابات عصبية في التطور تشمل أعراضها وجود مشاكل في السلوك الاجتماعي للشخص المصاب' , 'و يستخدم البرنامج نظام سحابي للذكاء الاصطناعي يسمح له بتحليل الإيماءات و التعابير' , 'النكت كلمة عامية تقال عند الكلام  المضحك بطريقة جميلة يملأها المرح  وأجمل  ما في النكت بأنها تجعلنا نبتسم ونضحك و لذلك لها أثر نفسي كبير جدا علينا فحسب بعض الدراسات العلمية بأن الضحك يقي من الاكتئاب ويقوي عضلات القلب وغيرها الكثير من الفوائد التي تعود بالمنفعة على جسم الإنسان' , 'كان المستكشف الأوربي كريستوفر كولومبوس مندهشا عندما شاهد شجرة الشوكولاتة لأول مرة في القارة الأمريكية موطنها الأصلي و كانت تستخدم فقط كمشروب في ذلك الوقت' , 'معالجة اللغة الطبيعية هو مجال يعمل على بناء خوارزميات حسابية لتحليل اللغة البشرية وتمثيلها تلقائيا وقد مكنت النظم القائمة على مجموعة واسعة من التطبيقات مثل محرك البحث القوي من جوجل  ومؤخرا المساعد الصوتي أليكسا من أمازون']\n",
        "\n",
        "print(a)\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "#def Define_the_error (a ,b):\n",
        "def similar(a, b):\n",
        "  return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "error =[]\n",
        "w = []\n",
        "for i in b:\n",
        "  if similar(a, i) >0.7:\n",
        "    # print(similar(a, i), i)\n",
        "\n",
        "    cases =[(a ,i)]\n",
        "    for i, s in enumerate (difflib.ndiff(a ,i)):\n",
        "      if s[0] == '': continue \n",
        "      elif s[0] == '+':\n",
        "        w = u'' \"{}\" ''.format(s[-1],i)\n",
        "        error.append(w)\n",
        "        error = list(dict.fromkeys(error))\n",
        "        \n",
        "\n",
        "print(error)\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEfBnj29XHzI"
      },
      "source": [
        "def enumerate(sequence, start=0):\n",
        "    n = start\n",
        "    for elem in sequence:\n",
        "        yield n, elem\n",
        "        n += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlvCqJ8m-SG-"
      },
      "source": [
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g99Q1p-Sz_i1"
      },
      "source": [
        "def stereoToMono(audiodata):\n",
        "  newaudiodata = []\n",
        "\n",
        "  for i in range(len(audiodata)):\n",
        "      d = (audiodata[i][0] + audiodata[i][1])/2\n",
        "      newaudiodata.append(d)\n",
        "\n",
        "  return np.array(newaudiodata, dtype='float32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQFnyRsXA6b"
      },
      "source": [
        "mfcc =[]\n",
        "mfcc_audio = []\n",
        "\n",
        "letter ={'ب':'/content/drive/My Drive/lett/refernc/silence_baa.wav','ت':'/content/drive/My Drive/lett/refernc/silence_ta.wav','ث':'/content/drive/My Drive/lett/refernc/silence_thaa.wav','ج':'/content/drive/My Drive/lett/refernc/silence_gem.wav','ح':'/content/drive/My Drive/lett/refernc/silence_haa.wav','خ':'/content/drive/My Drive/lett/refernc/silence_kaa.wav','د':'/content/drive/My Drive/lett/refernc/silence_dal.wav','ذ':'/content/drive/My Drive/lett/refernc/silence_thal.wav','ر':'/content/drive/My Drive/lett/refernc/silence_raa.wav','ز':'/content/drive/My Drive/lett/refernc/silence_zie.wav','س':'/content/drive/My Drive/lett/refernc/silence_sen.wav','ش':'/content/drive/My Drive/lett/refernc/silence_shen.wav','ص':'/content/drive/My Drive/lett/refernc/silence_sad.wav','ض':'/content/drive/My Drive/lett/refernc/silence_dad.wav','ط':'/content/drive/My Drive/lett/refernc/silence_taa.wav','ظ':'/content/drive/My Drive/lett/refernc/silence_thdaa.wav','ع':'/content/drive/My Drive/lett/refernc/silence_aen.wav','غ':'/content/drive/My Drive/lett/refernc/silence_gen.wav','ف':'/content/drive/My Drive/lett/refernc/silence_faa.wav','ق':'/content/drive/My Drive/lett/refernc/silence_kaf.wav','ك':'/content/drive/My Drive/lett/refernc/silence_kefa.wav','ل':'/content/drive/My Drive/lett/refernc/silence_lam.wav','م':'/content/drive/My Drive/lett/refernc/silence_mem.wav','ن':'/content/drive/My Drive/lett/refernc/silence_non.wav','ه':'/content/drive/My Drive/lett/refernc/silence_hhaa.wav','و':'/content/drive/My Drive/lett/refernc/silence_wow.wav','ي':'/content/drive/My Drive/lett/refernc/silence_eaa.wav'}\n",
        "lis = error\n",
        "\n",
        "#lis.append(lis)\n",
        "new_lis = []\n",
        "for k in lis:\n",
        "    if k in letter:\n",
        "        new_lis.append(letter[k])\n",
        "        print(new_lis)\n",
        "\n",
        "print(new_lis)\n",
        "\n",
        "#for i in new_lis:\n",
        "for index, item in enumerate(new_lis):\n",
        "      next = index + 1\n",
        "      if next < len(new_lis):\n",
        "          print (index, item, next)\n",
        "  \n",
        "          a = ipd.Audio(item ,autoplay=True)\n",
        "          ipd.display(a)\n",
        "          sample ,sample_rate = librosa.load(item ,sr =16000 ,mono=False)\n",
        "          audio, sr = get_audio()\n",
        "          audio = stereoToMono(audio)\n",
        "\n",
        "          if len(sample) > len(audio) :\n",
        "            dif = len(sample) - len(audio)\n",
        "\n",
        "          else:\n",
        "            dif = len(audio) - len(sample)\n",
        "          sample=np.pad(sample, (0, dif), 'constant', constant_values=0)\n",
        "          mfcc = librosa.feature.mfcc(y =sample ,sr =16000 ,n_mfcc=12)\n",
        "\n",
        "\n",
        "          mfcc_audio = librosa.feature.mfcc(y =audio ,sr =16000 ,n_mfcc=12)\n",
        "\n",
        "          print(mfcc.shape ,mfcc_audio.shape)\n",
        "\n",
        "          hop_size = 2205\n",
        "\n",
        "          D, wp = librosa.core.dtw(X=mfcc, Y=mfcc_audio, metric='euclidean')\n",
        "          wp_s = np.asarray(wp) * hop_size / sample_rate\n",
        "          best_cost = D[wp[-1, 0], wp[-1, 1]]\n",
        "          print(best_cost )\n",
        "\n",
        "          if best_cost <= 500:\n",
        "            print('لفظ صحيح' + item)\n",
        "\n",
        "            \n",
        "\n",
        "          elif best_cost >= 500 :\n",
        "            \n",
        "\n",
        "            a = ipd.Audio(new_lis[next] ,autoplay=True)\n",
        "            ipd.display(a)\n",
        "            sample ,sample_rate = librosa.load(new_lis[next] ,sr =16000 ,mono=False)\n",
        "            audio, sr = get_audio()\n",
        "            audio = stereoToMono(audio)\n",
        "\n",
        "            if len(sample) > len(audio) :\n",
        "              dif = len(sample) - len(audio)\n",
        "\n",
        "            else:\n",
        "              dif = len(audio) - len(sample)\n",
        "            sample=np.pad(sample, (0, dif), 'constant', constant_values=0)\n",
        "            mfcc = librosa.feature.mfcc(y =sample ,sr =16000 ,n_mfcc=12)\n",
        "\n",
        "\n",
        "            mfcc_audio = librosa.feature.mfcc(y =audio ,sr =16000 ,n_mfcc=12)\n",
        "\n",
        "            print(mfcc.shape ,mfcc_audio.shape)\n",
        "\n",
        "            hop_size = 2205\n",
        "\n",
        "            D, wp = librosa.core.dtw(X=mfcc, Y=mfcc_audio, metric='euclidean')\n",
        "            wp_s = np.asarray(wp) * hop_size / sample_rate\n",
        "            best_cost = D[wp[-1, 0], wp[-1, 1]]\n",
        "            print(best_cost )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytqzwUlU8_Bz"
      },
      "source": [
        "audio, sr = get_audio()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvbEqLHT1j8W"
      },
      "source": [
        "audio = stereoToMono(audio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DbSYkkuB4We"
      },
      "source": [
        "filename = '/content/prateek_voice_v2.wav'\n",
        "sf.write(filename, audio, sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrLLp5qC_Db2"
      },
      "source": [
        "filepath='/content/prateek_voice_v2.wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dpwUfoH_Gre"
      },
      "source": [
        "#reading the voice commands\n",
        "samples, sample_rate = librosa.load(filepath , sr = 16000)\n",
        "ipd.Audio(samples,rate=16000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jw_LZjyGSBN"
      },
      "source": [
        "all_wave =[]\n",
        "samples, sample_rate = librosa.load('/content/prateek_voice_v2.wav' , mono=True, sr=16000)\n",
        "\n",
        "#zero padding until data is equal\n",
        "if len(samples) <738116  : \n",
        "  dif = 738116-len(samples)\n",
        "sample=np.pad(samples, (0, dif), 'constant', constant_values=0)\n",
        "mfc =librosa.feature.mfcc(y=sample ,sr =16000 ,n_mfcc=50)\n",
        "all_wave.append(mfc)\n",
        "print(mfc.shape)\n",
        "print(sample.shape)\n",
        "\n",
        "all_wave = np.array(all_wave).reshape(-1,72100   ,1)\n",
        "print(all_wave.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbWd_8P_IyT"
      },
      "source": [
        "#converting voice commands to text\n",
        "predict(all_wave)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}